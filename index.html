<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="description">
  <meta name="keywords" content="SE-MAE, Squeeze-and-Expansion, MAE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Squeeze-and-Expansion Masked Autoencoders are 
    Strong Dynamic Scene Learners</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Squeeze-and-Expansion Masked Autoencoders are Strong Dynamic Scene Learners</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Taekyung Kim</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Dongyoon Han</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Byeongho Heo</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Jeongeun Park</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Sangdoo Yun</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>NAVER AI Lab,</span>
            <span class="author-block"><sup>2</sup>Korea University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img id="teaser" src="./static/teaser/comp_radar_chart.png" alt="Teaser Image" style="max-width: 50%; height: auto;">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">SE-MAE</span> significantly surpasses previous self-supervised visual representation learning methods designed for static and dynamic scenes on various robot manipulation and locomotion tasks.
      </h2>
    </div>
  </div>
</section>
  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="."
                type=".">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">.</span> ...
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deriving informative visual representations from dynamic scenes is essential in sequential scene-based tasks encompassing robotics and visual tracking. 
            Successfully executing these tasks necessitates capturing temporal evolution across consecutive scenes while retaining crucial information from observed scenes.
          </p>
          <p>
            In this paper, we highlight the significance of effective scene summarization in achieving these goals. 
            We introduce Squeeze-and-Expansion Masked Autoencoder (SE-MAE), a simple yet intuitive self-supervised learning pipeline that squeezes the reference scene and predicts the subsequent target scene with extremely scarce target patches as hints. 
            Our squeeze-and-expansion mechanism facilitates the effective acquisition of sequential scene representations through the squeeze step while enhancing the temporal evolution recognition capability across consecutive scenes through the expansion step, 
            thereby fulfilling the essential requisites for sequential scene understanding.
          </p>
          <p>
            Extensive experiments in diverse simulated environments demonstrate the superiority of our method on robot manipulation and locomotion tasks over previous baselines. 
            Moreover, deploying our pre-trained model on physical robots confirms its robustness and effectiveness in real-world settings. 
            Our method even outperforms baselines on various video label propagation tasks. We provide further investigations that validate the scalability of SE-MAE.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{kim2025semae,
  author    = {Taekyung Kim and Dongyoon Han and Byeongho Heo and Jeongeun Park and Sangdoo Yun},
  title     = {Squeeze-and-Expansion Masked Autoencoders are Strong Dynamic Scene Learners},
  journal   = {....},
  year      = {2025},
}</code></pre>
  </div>
</section>
  

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
